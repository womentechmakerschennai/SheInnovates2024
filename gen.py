# -*- coding: utf-8 -*-
"""aistudio_gemini_prompt_chat_b64.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/github/google/generative-ai-docs/blob/main/templates/aistudio_gemini_prompt_chat_b64.ipynb

##### Copyright 2023 Google LLC
"""

#@title Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
# https://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

"""## Setup

### Install & import
"""

!pip install -U -q google-generativeai

# import necessary modules.
import google.generativeai as genai
import json
import base64
import pathlib
import pprint
import requests
import mimetypes
from IPython.display import Markdown

"""## Set the API key

Add your API_KEY to the secrets manager in the left pannel "ðŸ”‘".
"""

from google.colab import userdata

API_KEY='AIzaSyDQAyaX5e-CMVNEFVWcLOQabykmRb8Qu2o'

# Configure the client library by providing your API key.
genai.configure(api_key=API_KEY)

"""### Parse the arguments"""

model = 'gemini-1.0-pro' # @param {isTemplate: true}
contents_b64 = 'W10=' # @param {isTemplate: true}
generation_config_b64 = 'eyJ0ZW1wZXJhdHVyZSI6MC45LCJ0b3BfcCI6MSwidG9wX2siOjEsIm1heF9vdXRwdXRfdG9rZW5zIjoyMDQ4LCJzdG9wX3NlcXVlbmNlcyI6W119' # @param {isTemplate: true}
safety_settings_b64 = 'W3siY2F0ZWdvcnkiOiJIQVJNX0NBVEVHT1JZX0hBUkFTU01FTlQiLCJ0aHJlc2hvbGQiOiJCTE9DS19NRURJVU1fQU5EX0FCT1ZFIn0seyJjYXRlZ29yeSI6IkhBUk1fQ0FURUdPUllfSEFURV9TUEVFQ0giLCJ0aHJlc2hvbGQiOiJCTE9DS19NRURJVU1fQU5EX0FCT1ZFIn0seyJjYXRlZ29yeSI6IkhBUk1fQ0FURUdPUllfU0VYVUFMTFlfRVhQTElDSVQiLCJ0aHJlc2hvbGQiOiJCTE9DS19NRURJVU1fQU5EX0FCT1ZFIn0seyJjYXRlZ29yeSI6IkhBUk1fQ0FURUdPUllfREFOR0VST1VTX0NPTlRFTlQiLCJ0aHJlc2hvbGQiOiJCTE9DS19NRURJVU1fQU5EX0FCT1ZFIn1d' # @param {isTemplate: true}
user_input_b64 = '' # @param {isTemplate: true}

contents = json.loads(base64.b64decode(contents_b64))
generation_config = json.loads(base64.b64decode(generation_config_b64))
safety_settings = json.loads(base64.b64decode(safety_settings_b64))
user_input = base64.b64decode(user_input_b64).decode()
stream = False

contents

generation_config

safety_settings

def generate_prompt(topic, level,familiar,focus, purpose):
    # Placeholder technique: Using curly braces {} to insert variables into a string
    prompt_template = """Goal:\nLearn about {}\n\nBackground:\nlevel of knowledge in this topic: {}\nFamiliar with {}\nTopics to focus on: {}\n\nLearning Resources:\nLooking for 2 Youtube videos:\nOne long video (in-depth explanation)\nOne shorter video (concise overview)\n\nSelection criteria:\nHigh like-to-view ratio (indicator of quality)\n\nRequest:\nPlease provide links to 2 Youtube videos that meet the above criteria. ONLY GIVE THE LINKS. DO NOT GIVE ME ANY OTHER GENERATED TEXT!! """
    prompt = prompt_template.format(topic, level,familiar,focus, purpose)
    return prompt


    # Taking user information
topic_of_interest = input("Enter your topic of interest: ")
knowledge_level = input("Enter your level of knowledge in this topic: ")
topics_familiar=input("Enter familiar topics(keywords,seperate with a comma): ")
topics_to_be_focused=input("Enter topics that you want to focus on: ")
learning_purpose = input("Enter your purpose of learning (Project/Understanding concepts): ")


    # Generating prompt using placeholder technique
prompt = generate_prompt(topic_of_interest, knowledge_level,topics_familiar,topics_to_be_focused, learning_purpose)
print("\nPrompt generated:")
print(prompt)

print(prompt)



"""### Call the API"""

# Call the model and print the response.
def gen(user_input):
  gemini = genai.GenerativeModel(model_name=model)
  chat = gemini.start_chat(history=contents)
  response = chat.send_message(
    user_input,
    stream=stream)
  return response

msg= gen(prompt)

display(Markdown(response.text))

response.prompt_feedback

response.candidates